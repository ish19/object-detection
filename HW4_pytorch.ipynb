{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNdrQGBYTOIrM9r9hGQA/HK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"31sytiX1QAHu"},"outputs":[],"source":["import torchvision\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn\n","import torchvision.transforms as T\n","import torch\n","from google.colab.patches import cv2_imshow\n","import cv2\n","\n"]},{"cell_type":"code","source":["# Load the Faster R-CNN model pretrained on COCO and move it to GPU if possible\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = fasterrcnn_resnet50_fpn(pretrained=True)\n","model = model.to(device)\n","model.eval()\n","\n"],"metadata":{"id":"lSkkK-AqQQvS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load video and set up video capture (replace 'your_video.avi' with your video file)\n","video_path = '/content/traffic.avi'\n","cap = cv2.VideoCapture(video_path)"],"metadata":{"id":"630_ah-UQSJv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Define the codec and create a VideoWriter object to save the output video in .avi format\n","output_path = '/content/output_video_with_boxes_final.avi'\n","fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Use 'XVID' codec for .avi\n","fps = int(cap.get(cv2.CAP_PROP_FPS))  # Get the original frame rate\n","frame_size = (int(cap.get(3)), int(cap.get(4)))\n","out = cv2.VideoWriter(output_path, fourcc, fps, frame_size)\n"],"metadata":{"id":"EMa9i0RoQPBc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a transform to preprocess frames\n","transform = T.Compose([T.ToPILImage(), T.ToTensor()])\n","# Process every frame (no frame skipping)\n","frame_count = 0\n","\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    frame_count += 1\n","\n","    # Preprocess frame and move to GPU\n","    input_tensor = transform(frame).unsqueeze(0).to(device)\n","\n","    # Perform object detection\n","    with torch.no_grad():\n","        prediction = model(input_tensor)\n","\n","    # Extract bounding boxes and scores\n","    boxes = prediction[0]['boxes']\n","    scores = prediction[0]['scores']\n"],"metadata":{"id":"LaDJP5W3QIRs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" # Filter detections based on a confidence threshold\n","    confidence_threshold = 0.64\n","    filtered_indices = [i for i, score in enumerate(scores) if score >= confidence_threshold]\n","\n","    # Draw bounding boxes for detected cars\n","    for i in filtered_indices:\n","        box = boxes[i].cpu().numpy().astype(int)\n","        confidence = scores[i].cpu().numpy()\n","        cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n","        cv2.putText(frame, f'Car: {confidence:.2f}', (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n","\n","    # Write the frame with bounding boxes to the output video\n","    out.write(frame)\n","\n","    # Display the frame with bounding boxes using cv2_imshow\n","    cv2_imshow(frame)\n","\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","cap.release()\n","out.release()  # Release the VideoWriter\n","cv2.destroyAllWindows()"],"metadata":{"id":"NTD3G2l2QCZm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8I-OC4h5QCcB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EOP60PjWQCeP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NxIpo5HEQCge"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fsrO-4CjQCj7"},"execution_count":null,"outputs":[]}]}